{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАГРУЗКА ПОДГОТОВЛЕННОГО ДАТАФРЕЙМА В БД SQL\n",
    "# код для вставки в блокнот/программу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# импортируем библиотеки\n",
    "import glob\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_0 = dt_.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_schema = 'recipes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❕ Получение датафрейма (вставь свой код сюда)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# маска имени файла с выгрузкой\n",
    "fn_mask = r'..\\uploadings\\DAT4853_week_from_20??-??-??_to_20??-??-??_long.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# получение списка всех файлов с выгрузками\n",
    "ls_fn_full = glob.glob(fn_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# инициализируем пустой датафрейм, из которого данные будут мигрировать в SQL\n",
    "df = pd.DataFrame()\n",
    "# итерируемся по списку файлов\n",
    "for fn in ls_fn_full:\n",
    "    # читаем очередной файл во временный датафрейм\n",
    "    df_temp = pd.read_parquet(fn)\n",
    "    # добавляем данные в конец результирующего фрейма\n",
    "    df = pd.concat([df, df_temp], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read dictionaries in dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ```\n",
      "| table          | Маска имени файла                     | Клавиша |\n",
      "| -------------- | ------------------------------------- | ------- |\n",
      "| all            | <Все словари>                         |    0    |\n",
      "| df_names       | Словарь_Названия_20YY_MM_DD.xlsx      |    1    |\n",
      "| df_mo          | Словарь_МО_20YY_MM_DD.xlsx            |    2    |\n",
      "| df_mkb_10      | Словарь_МКБ_10_20YY_MM_DD.xlsx        |    3    |\n",
      "| df_orders      | Словарь_Приказы_20YY_MM_DD.xlsx       |    4    |\n",
      "| df_spec        | Словарь_Специальности_20YY_MM_DD.xlsx |    5    |\n",
      "| df_app         | Словарь_Назначения_20YY_MM_DD.xlsx    |    6    |\n",
      "| df_profile_vop | Словарь_Профиль_ВОП_20YY_MM_DD.xlsx   |    7    |\n",
      "```\n",
      "\n",
      "Вы выбрали: ['df_names', 'df_mo', 'df_mkb_10', 'df_orders', 'df_spec', 'df_app', 'df_profile_vop']\n",
      "\n",
      "Не удалось загрузить словарь \"df_app\" из-за Table df_app not found\n",
      "\n",
      "Словари записаны в словарь словарей `dict_dicts`\n"
     ]
    }
   ],
   "source": [
    "# функция, которая проверяет отсутствие имен файлов из кортежа tup_fns в содержимом папки path_\n",
    "def check_missing_files(tup_fns, path_):\n",
    "    # Получаем список файлов в указанной папке\n",
    "    files_in_directory = os.listdir(path_)\n",
    "    \n",
    "    # Создаём список файлов, которых нет в папке\n",
    "    missing_files = [file for file in tup_fns if file not in files_in_directory]\n",
    "    \n",
    "    # Проверка и вывод результата\n",
    "    if missing_files:\n",
    "        print(f\"Следующие файлы отсутствуют в папке '{path_}': {', '.join(missing_files)}\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print(f\"Все необходимые для работы программы служебные файлы присутствуют в папке '{path_}'.\")\n",
    "    \n",
    "    return missing_files\n",
    "\n",
    "# кортеж с именами необходимых для работы программы служебных файлов\n",
    "tup_fns = (\n",
    "    'user_functions.py',\n",
    "    'paths_and_constants.py',\n",
    "    'dict_sql_queries.py',\n",
    "    'get_dicts_v_06.py',\n",
    ")\n",
    "\n",
    "\n",
    "# получаем имя компьютера\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "# если программа выполняется на сервере\n",
    "if hostname == '304-007':\n",
    "    # указываем путь к общим документам\n",
    "    path_ = r'C:\\Users\\Public\\dictionaries'\n",
    "# иначе (если программа выполняется на своём рабочем ПК)\n",
    "else:\n",
    "    # указываем путь к документам активного пользователя\n",
    "    path_ = os.path.expanduser('~\\\\Documents\\\\')\n",
    "\n",
    "# проверяем отсутствие имен файлов из кортежа tup_fns в содержимом папки path_\n",
    "check_missing_files(tup_fns, path_)\n",
    "\n",
    "# добавляем путь к системному пути поиска модулей (путь к папке, в которой Python ищет модули)\n",
    "sys.path.append(path_)\n",
    "\n",
    "# далее импорт пользовательских библиотек идёт с пути `path_`\n",
    "try:\n",
    "    import get_dicts_v_06\n",
    "    from user_functions import df_2_sql\n",
    "except:\n",
    "    print(f'\\nДоп. модули, необходиимые для работы кода, НЕ НАЙДЕНЫ по адресу \"{path_}\"')\n",
    "\n",
    "# использование пользовательской функции для получения словарей из SQL\n",
    "# можно ввести номера словарей через пробел в скобки, если словари заранее известны\n",
    "dict_dicts, tables = get_dicts_v_06.main('1 2')  #  <------------------------------------------------------------------------------------ ВВОД!\n",
    "\n",
    "# Цикл по индексам от 0 до длины списка tables\n",
    "for i in range(len(tables)):\n",
    "    try:\n",
    "        # Используем exec() для динамического создания переменной с именем таблицы (tables[i][0]) \n",
    "        # и присваивания ей первого элемента (таблицы) из соответствующего словаря dict_dicts\n",
    "        exec(f\"{tables[i][0]} = dict_dicts[tables[i][0]][0]\")\n",
    "        # Вывод информации о таблице, включая её название, заголовок, и дату загрузки в БД\n",
    "        print(f\"\\nТаблицей '{tables[i][0]}' можно пользоваться. \"\n",
    "              f\"Её название: {dict_dicts[tables[i][0]][1]} \"\n",
    "              f\"Она была загружена в БД {dict_dicts[tables[i][0]][2]}\")\n",
    "        # Отображаем первые две строки таблицы с помощью функции display()\n",
    "        display(dict_dicts[tables[i][0]][0].head(2))\n",
    "    except:\n",
    "        # print(f\"\\nСкорее всего, таблицы '{tables[i][0]}' ещё не существует в БД\")\n",
    "        # Если происходит ошибка (например, если таблицы ещё нет в БД), просто пропускаем и ничего не выводим.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_dict_rename = df_names[['rus_name', 'eng_name']]\n",
    "df_for_dict_rename = df_for_dict_rename.set_index('rus_name')['eng_name'].to_dict()\n",
    "# display(df_for_dict_rename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_s_answer = input('Нажмите \"Перейти\" и при необходимости поменяйте \"вводные\" в ячейке после исполняемой, после чего введите любой символ в это поле: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аргументы ⌨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# имя таблицы в БД\n",
    "table_name = '5213_bva'\n",
    "# составной первичный ключ, либо список из одного столбца / пустой список\n",
    "ls_pk = ['emias_id', 'mkb_10']\n",
    "# столбцы для индекса таблицы\n",
    "ls_index = ['oms', 'mo', ]\n",
    "# сколько строк сгружать за итерацию\n",
    "rows = (500_000, 8_900_000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ delete one cell below: создание песочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.duplicated(subset=['emias_id', 'mkb_10']).sum() > 0:\n",
    "    df = df.drop_duplicates(subset=['emias_id', 'mkb_10']).reset_index(drop=True)\n",
    "\n",
    "df = df.loc[0:499_999, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create table in postgresql db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=df_for_dict_rename, inplace=True)\n",
    "\n",
    "df_2_sql(df, table_schema, table_name, ls_pk, ls_index, rows=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем правильность нейминга столбцов\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.7 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f'done in {((dt_.now() - time_0).seconds / 60):.1f} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
